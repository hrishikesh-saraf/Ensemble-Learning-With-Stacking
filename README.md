Ensemble methods are an excellent way to improve predictive performance on machine learning problems.
Stacked Generalization or stacking is an ensemble technique that uses a new model to learn how to best combine the predictions from two or more models trained on the dataset.
In this project, I have stacked machine learning algorithms: K – NN, Naïve Bayes Classifier, Decision Tree to combine their results.
Performance of the ensemble learner proved to be 4% more than individual learners. 
